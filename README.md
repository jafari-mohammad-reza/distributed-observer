# ğŸ§  The Observer

_A distributed log and full-text search engine inspired by Elasticsearch, MongoDB Oplog, and Kafka-based event streaming._

---

## ğŸ’¡ Project Goals

This project is a hands-on implementation to practice distributed systems by building an Elasticsearch-style engine using Go and Kafka. The system is designed to support:

- ğŸ” Full-text and keyword search
- ğŸ§  MMAP-backed in-memory index storage
- ğŸ“¦ Append-only oplog-based write recovery
- ğŸ›°ï¸ Kafka-driven CDC and node synchronization
- ğŸŒ Peer-to-peer communication with custom load balancing
- ğŸ§Š Hot/Cold memory-based index lifecycle management

---

## ğŸ§¬ High-Level Architecture

```text
                +--------+
Client Request â†’|  Node  |â”€â”€â”€Kafkaâ†’ Append-only Write Event (partitioned by index)
                +--------+
                    |
              +-------------+
              |  Processor  |â†â”€â”€ Consumes event from Kafka
              +-------------+
                    |
       +----------------------------+
       | Index Memory Manager (MMAP)|
       +----------------------------+
                    |
             +--------------+
             | Disk Storage |
             +--------------+
                    |
           +------------------+
           | Oplog (Recovery) |
           +------------------+
```

Write Flow 1. Client sends a JSON payload to POST
**/logs/:index**

```json
{
  "time": "2023/08/12:13:05:10",
  "name": "x",
  "family": "y"
}
```

2. The node publishes a Kafka event (topic = index, partitioned by hash of index name).
3. Background processor consumes the event and transforms the log into a keyword-based map:

```json
{
  "2023/08/12:13:05:10": "time",
  "x": "name",
  "y": "family"
}
```

4. This map is written to a file using memory-mapped I/O:
   â€¢ If the index is OPEN, data is appended.
   â€¢ If the index doesnâ€™t exist, itâ€™s created and loaded into memory.
5. Indexes that havenâ€™t been written to for a configurable TTL are marked CLOSED and evicted from memory.
6. Every action (write, close, load) is appended to a Kafka-backed oplog, which is later parsed by a Logstash-style consumer and stored in append-only blob logs.
   ğŸ“¦ Disk Format (Maximum Storage Efficiency)

To store logs efficiently while minimizing space:
â€¢ Logs will be serialized in compact binary format (e.g., MessagePack, Protobuf, or Gob).
â€¢ Chunks of records will be grouped and compressed with Zstandard (Zstd).
â€¢ Each chunk will be stored as a .dat.zst file on disk, with optional side dictionaries for keyword-to-ID mapping.

```text
/logs/auth-2025-07-10/
â”œâ”€â”€ chunk-00001.dat.zst   # Zstd-compressed binary logs
â”œâ”€â”€ chunk-00001.dict      # Optional keyword dictionary
```

    â€¢	Index metadata (e.g., offsets, keyword maps) are stored separately.
    â€¢	Cold chunks can be lazily loaded and mapped into memory only on query.

This format provides:
â€¢ ğŸš€ Compact size
â€¢ ğŸ’¾ Lower disk I/O
â€¢ ğŸ§Š Support for cold storage and archival
â€¢ ğŸ’¡ Tradeoff: slow recovery/rebuilding time (acceptable for your goals)
ğŸ” Search Flow
â€¢ Clients must specify an index name or index prefix + time range to reduce scan space.
â€¢ The system: 1. Resolves the index set using prefix/range. 2. Lazily loads CLOSED indexes back into memory. 3. Merges the relevant MMAP regions into a unified map. 4. Performs keyword/full-text matching.

â¸»

ğŸ§  Memory & Index Lifecycle
â€¢ MMAP-backed memory means indexes are mapped directly from disk.
â€¢ OPEN Index: actively written to and kept in memory.
â€¢ CLOSED Index: offloaded to disk when inactive.
â€¢ Lifecycle controlled by background goroutines using Go channels and timers.
â€¢ Indexes can be time-sharded (logs-2025-07, logs-2025-07-10) for more efficient time range queries.

â¸»

ğŸ› ï¸ Planned Features
â€¢ MMAP segment compaction and snapshots
â€¢ Text analysis pipeline (tokenizer, stemming, stop-word filtering)
â€¢ Binary protocol over TCP for low-latency cluster RPC
â€¢ Web UI dashboard for observability and debugging
â€¢ Peer-to-peer gossip and node discovery
â€¢ Raft-style metadata leadership and replication
â€¢ Smart index allocator for memory balancing
â€¢ Log-based failover and recovery system
